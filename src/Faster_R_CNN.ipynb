{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BG38NSIQC-vA"
   },
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoyYWmD4Dles"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-T4hKiVjQbKI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACODA\\envs\\cs231n\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\myMachineLearning\\faster_rcnn\\src/data\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import losses\n",
    "import config\n",
    "import data_generator\n",
    "import roi_utils\n",
    "from rpn import rpn\n",
    "import resnet\n",
    "import pascal_voc_parser\n",
    "import os\n",
    "import json\n",
    "from RoiPooling import RoiPooling\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "config = config.Config()\n",
    "base_nn_weights_path = os.path.abspath('.') + '/' + resnet.WEIGHT_PATH\n",
    "num_epochs = 2000\n",
    "data_path = os.path.abspath('.') + '/data'\n",
    "temp_img_data_path = os.path.abspath('.') + '/temp_img_data.json'\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3jpTEFcDYUn"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "AmRisKF7C4ER",
    "outputId": "9b305bf1-faa0-4061-9830-034e8a5686c0"
   },
   "outputs": [],
   "source": [
    "# pascal voc 2007\n",
    "if not os.path.exists(data_path):\n",
    "  os.mkdir(data_path)\n",
    "if not os.path.exists(data_path + '/VOC2007.tar'):\n",
    "    annotation_zip = keras.utils.get_file(data_path + '/VOC2007.tar',\n",
    "                                        extract=True,\n",
    "                                        cache_subdir=data_path,\n",
    "                                        origin='http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2Y5jZUARIz3"
   },
   "outputs": [],
   "source": [
    "# pascal voc 2012\n",
    "# annotation_zip = keras.utils.get_file(data_path + '/VOC2012.tar',\n",
    "#                                         extract=True,\n",
    "#                                         cache_subdir=data_path,\n",
    "#                                         origin='http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar')\n",
    "\n",
    "data_path += '/VOCdevkit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_L2XKl1S_X5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "5011 {'chair': 1432, 'car': 1644, 'horse': 406, 'person': 5447, 'bicycle': 418, 'cat': 389, 'dog': 538, 'train': 328, 'aeroplane': 331, 'diningtable': 310, 'tvmonitor': 367, 'bird': 599, 'bottle': 634, 'motorbike': 390, 'pottedplant': 625, 'boat': 398, 'sofa': 425, 'sheep': 353, 'cow': 356, 'bus': 272, 'bg': 0} {'chair': 0, 'car': 1, 'horse': 2, 'person': 3, 'bicycle': 4, 'cat': 5, 'dog': 6, 'train': 7, 'aeroplane': 8, 'diningtable': 9, 'tvmonitor': 10, 'bird': 11, 'bottle': 12, 'motorbike': 13, 'pottedplant': 14, 'boat': 15, 'sofa': 16, 'sheep': 17, 'cow': 18, 'bus': 19, 'bg': 20}\n"
     ]
    }
   ],
   "source": [
    "all_imgs, classes_count, class_mapping = pascal_voc_parser.get_data(data_path)\n",
    "if 'bg' not in classes_count:\n",
    "    classes_count['bg'] = 0\n",
    "    class_mapping['bg'] = len(class_mapping)\n",
    "config.class_mapping = class_mapping\n",
    "class_mapping_inv = {v: k for k, v in class_mapping.items()}\n",
    "print(len(all_imgs), classes_count, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501 2510\n"
     ]
    }
   ],
   "source": [
    "# train and test imgs\n",
    "train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "# print(np.array(train_imgs).shape)\n",
    "# train_imgs = tf.map_fn(lambda x: x, np.array(train_imgs))\n",
    "test_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "\n",
    "print(len(train_imgs), len(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filepath': 'F:\\\\myMachineLearning\\\\faster_rcnn\\\\src/data/VOCdevkit/VOC2007\\\\JPEGImages\\\\000012.jpg', 'width': 500, 'height': 333, 'bboxes': [{'class': 'car', 'x1': 156, 'x2': 351, 'y1': 97, 'y2': 270, 'difficult': False}], 'imageset': 'trainval'}\n"
     ]
    }
   ],
   "source": [
    "import data_generator\n",
    "print(train_imgs[0])\n",
    "\n",
    "# train and test dataset\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda : data_generator.get_anchor_gt(\n",
    "    train_imgs, classes_count, config, resnet.get_img_output_length, temp_img_data_path), (tf.float32, tf.float32, tf.float32))\n",
    "train_dataset = train_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda : data_generator.get_anchor_gt(\n",
    "    test_imgs, classes_count, config, resnet.get_img_output_length, temp_img_data_path), (tf.float32, tf.float32, tf.float32))\n",
    "test_dataset = test_dataset.make_one_shot_iterator().get_next()\n",
    "# with tf.Session() as sess:\n",
    "#     a, b, c = sess.run(train_dataset)\n",
    "#     print(a, np.sum(b), np.sum(c))\n",
    "#     a, b, c = sess.run(train_dataset)\n",
    "#     print(a, np.sum(b), np.sum(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, ?, 1024)\n",
      "(?, ?, 4)\n",
      "Tensor(\"roi_pooling/strided_slice:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_1:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_2:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_5:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_6:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_7:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_8:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_10:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_11:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_12:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_13:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_15:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_16:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_17:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_18:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_20:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_21:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_22:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_23:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_25:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_26:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_27:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_28:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_30:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_31:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_32:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_33:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_35:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_36:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_37:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_38:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_40:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_41:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_42:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_43:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_45:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_46:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_47:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_48:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_50:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_51:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_52:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_53:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_55:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_56:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_57:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_58:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_60:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_61:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_62:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_63:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_65:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_66:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_67:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_68:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_70:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_71:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_72:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_73:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_75:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_76:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_77:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_78:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_80:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_81:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_82:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_83:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_85:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_86:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_87:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_88:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_90:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_91:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_92:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_93:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_95:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_96:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_97:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_98:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_100:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_101:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_102:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_103:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_105:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_106:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_107:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_108:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_110:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_111:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_112:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_113:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_115:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_116:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_117:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_118:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_120:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_121:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_122:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_123:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_125:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_126:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_127:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_128:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_130:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_131:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_132:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_133:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_135:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_136:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_137:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_138:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_140:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_141:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_142:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_143:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_145:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_146:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_147:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_148:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_150:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_151:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_152:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_153:0\", shape=(), dtype=float32)\n",
      "Tensor(\"roi_pooling/strided_slice_155:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_156:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_157:0\", shape=(), dtype=float32) Tensor(\"roi_pooling/strided_slice_158:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"dense_class_21/Tensordot:0\", shape=(1, 32, 21), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f1977d739906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmodel_rpn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrpn_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# model_rpn.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmodel_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m# model_classifier = keras.Model([base_input, roi_input], classifier)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mmodel_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACODA\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;31m# Create a cache for iterator get_next op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_get_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeakKeyDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACODA\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     79\u001b[0m       \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m       \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACODA\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACODA\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    222\u001b[0m         raise ValueError('Output tensors to a ' + cls_name + ' must be '\n\u001b[0;32m    223\u001b[0m                          \u001b[1;34m'the output of a TensorFlow `Layer` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                          '(thus holding past layer metadata). Found: ' + str(x))\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"dense_class_21/Tensordot:0\", shape=(1, 32, 21), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# input\n",
    "input_shape = (None, None, 3)\n",
    "img_input = keras.layers.Input(shape=input_shape)\n",
    "roi_input = keras.layers.Input(shape=(None, 4))\n",
    "\n",
    "# base network\n",
    "shared_layers = resnet.nn_base(img_input, trainable=False)\n",
    "\n",
    "# rpn\n",
    "num_anchors = len(config.anchor_box_scales) * len(config.anchor_box_ratios)\n",
    "rpn_layer = rpn(shared_layers, num_anchors)\n",
    "\n",
    "# TEST\n",
    "# base_input = keras.layers.Input(shape=(300, 300, 1024))\n",
    "# base_input = keras.layers.Input(shape=(config.num_rois, 14, 14, 1024))\n",
    "\n",
    "# roi pooling\n",
    "# roi_pool = RoiPooling(14, config.num_rois)(shared_layers, roi_input)\n",
    "# roi_pool = RoiPooling(14, config.num_rois)([shared_layers, roi_input])\n",
    "# roi_pool = RoiPooling(14, config.num_rois)([base_input, roi_input])\n",
    "\n",
    "# classifier\n",
    "# classifier = resnet.classifier(roi_pool, input_shape=(config.num_rois, 14, 14, 1024),\n",
    "#                                n_classes=len(classes_count), trainable=False)\n",
    "# roi_pool = resnet.roi(base_input, roi_input, 14, config.num_rois)\n",
    "# classifier = resnet.classifier(roi_pool, input_shape=(config.num_rois, 14, 14, 1024),\n",
    "#                                n_classes=len(classes_count), trainable=False)\n",
    "classifier = resnet.classifier(shared_layers, roi_input, config.num_rois,\n",
    "                               input_shape=(config.num_rois, 14, 14, 1024),\n",
    "                               n_classes=len(classes_count), trainable=False)\n",
    "\n",
    "model_rpn = keras.Model(img_input, rpn_layer[:2])\n",
    "# model_rpn.summary()\n",
    "model_classifier = keras.Model([img_input, roi_input], classifier)\n",
    "# model_classifier = keras.Model([base_input, roi_input], classifier)\n",
    "model_classifier.summary()\n",
    "\n",
    "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "# model_all = keras.Model([img_input, roi_input], rpn_layer[:2] + classifier)\n",
    "\n",
    "# load weights\n",
    "print('loading weights from {}'.format(base_nn_weights_path))\n",
    "model_rpn.load_weights(base_nn_weights_path, by_name=True)\n",
    "model_classifier.load_weights(base_nn_weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers\n",
    "optimizer = keras.optimizers.Adam(lr=1e-5)\n",
    "optimizer_classifier = keras.optimizers.Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=optimizer, \n",
    "                  loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, \n",
    "                  loss=[losses.class_loss_cls, losses.class_loss_regr(len(classes_count) - 1)])\n",
    "# model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = 1000\n",
    "iter_num = 0\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "start_time = time.time()\n",
    "best_loss = np.Inf\n",
    "print('Start training.')\n",
    "vis = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_num in range(num_epochs):\n",
    "    progbar = keras.utils.Progbar(epoch_length)\n",
    "    print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "    while True:\n",
    "#         try:\n",
    "        # verbose\n",
    "        if len(rpn_accuracy_rpn_monitor) == epoch_length and config.verbose:\n",
    "            mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "            rpn_accuracy_rpn_monitor = []\n",
    "            print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
    "            if mean_overlapping_bboxes == 0:\n",
    "                print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "        # base to RPN\n",
    "        with tf.Session() as sess:\n",
    "            X, Y1, Y2 = sess.run(train_dataset)\n",
    "#         print(X.shape, Y1.shape, Y2.shape)\n",
    "#                 print(model_rpn.summary())\n",
    "        loss_rpn = model_rpn.train_on_batch(X, [Y1, Y2])\n",
    "#         print(loss_rpn)\n",
    "        P_rpn = model_rpn.predict_on_batch(X)\n",
    "#         print(P_rpn)\n",
    "        # get ROI\n",
    "        R = roi_utils.rpn_to_roi(P_rpn[0], P_rpn[1], config, \n",
    "                                 max_boxes=300, overlap_threshold=0.7)\n",
    "#                 get final ground truth and (x,y,w,h)-format roi\n",
    "        X2, Y1, Y2, ious = roi_utils.cal_iou(R, temp_img_data_path, config, class_mapping)\n",
    "        if X2 is None:\n",
    "            rpn_accuracy_rpn_monitor.append(0)\n",
    "            rpn_accuracy_for_epoch.append(0)\n",
    "            continue\n",
    "        print(X2.shape, Y1.shape, Y2.shape)\n",
    "        # select limited samples\n",
    "        neg_samples = np.where(Y1[0, :, -1] == 1)[0] # Y1[:, -1] bg class\n",
    "        pos_samples = np.where(Y1[0, :, -1] == 0)[0]\n",
    "        rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "        rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "        if config.num_rois > 1:\n",
    "            if len(pos_samples) < config.num_rois // 2:\n",
    "                sel_pos_samples = pos_samples.tolist()\n",
    "            else: \n",
    "                sel_pos_samples = np.random.choice(pos_samples, config.num_rois // 2, replace=False).tolist()\n",
    "            try:\n",
    "                sel_neg_samples = np.random.choice(neg_samples, config.num_rois - len(sel_pos_samples), replace=False).tolist()\n",
    "            except:\n",
    "                sel_neg_samples = np.random.choice(neg_samples, config.num_rois - len(sel_pos_samples), replace=True).tolist()\n",
    "            sel_samples = sel_pos_samples + sel_neg_samples\n",
    "        else:\n",
    "            # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "            sel_pos_samples = pos_samples.tolist()\n",
    "            sel_neg_samples = neg_samples.tolist()\n",
    "            if np.random.randint(0, 2):\n",
    "                sel_samples = random.choice(neg_samples)\n",
    "            else:\n",
    "                sel_samples = random.choice(pos_samples)\n",
    "        print(sel_samples)\n",
    "        # final classifier\n",
    "        loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]],\n",
    "                                                     [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "        # TEST\n",
    "        \n",
    "#         loss_class = model_classifier.train_on_batch([np.random.rand(1, 300, 300, 1024), np.random.rand(1, 32, 4)],\n",
    "#                                                      [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "        print(loss_class)\n",
    "        # losses\n",
    "        losses[iter_num, 0] = loss_rpn[1]\n",
    "        losses[iter_num, 1] = loss_rpn[2]\n",
    "        losses[iter_num, 2] = loss_class[1]\n",
    "        losses[iter_num, 3] = loss_class[2]\n",
    "        losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "        iter_num += 1\n",
    "        progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                                ('detector_cls', np.mean(losses[:iter_num, 2])), ('detector_regr', np.mean(losses[:iter_num, 3]))])\n",
    "        if iter_num == epoch_length:\n",
    "            loss_rpn_cls = np.mean(losses[:, 0])\n",
    "            loss_rpn_regr = np.mean(losses[:, 1])\n",
    "            loss_class_cls = np.mean(losses[:, 2])\n",
    "            loss_class_regr = np.mean(losses[:, 3])\n",
    "            class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "            mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch))/len(rpn_accuracy_for_epoch)\n",
    "            rpn_accuracy_for_epoch = []\n",
    "\n",
    "            if config.verbose:\n",
    "                print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "                print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "                print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "                print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "            curr_loss =loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "            item_num = 0\n",
    "            start_time = time.time()\n",
    "            if curr_loss < best_loss:\n",
    "                if config.verbose:\n",
    "                    print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
    "                best_loss = curr_loss\n",
    "                model_all.save_weights(config.model_path)\n",
    "            break\n",
    "#         except Exception as e:\n",
    "#             print('Exception: {}'.format(e))\n",
    "#             break\n",
    "                \n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Faster R-CNN.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
